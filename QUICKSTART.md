# Quick Start Guide

## ğŸš€ Quick Installation with Conda

### Option 1: Automated Script (Recommended)

```bash
# On Linux/Mac/WSL
./setup_env.sh

# On Windows
setup_env.bat
```

### Option 2: Manual Commands

```bash
# Create the environment
conda env create -f environment.yml

# Activate the environment
conda activate scrape-to-shape

# Install Playwright browsers
playwright install chromium

# Download spaCy Spanish model
python -m spacy download es_core_news_sm
```

## ğŸ“ Basic Usage

### 1. Activate the environment

```bash
conda activate scrape-to-shape
```

### 2. Run the scraper

```bash
cd src/scraper
python main.py
```

The data will be saved to `data/raw/google_maps_all_reviews.csv`

### 3. Exploratory analysis

```bash
# From the project root
jupyter notebook
```

Then open `notebooks/EDA.ipynb`

## ğŸ”§ Useful Commands

### List conda environments
```bash
conda env list
```

### Update dependencies
```bash
conda env update -f environment.yml --prune
```

### Remove the environment
```bash
conda env remove -n scrape-to-shape
```

### Export current environment
```bash
conda env export > environment_backup.yml
```

## ğŸ› Troubleshooting

### Issue: "conda: command not found"
**Solution:** Install Miniconda from https://docs.conda.io/en/latest/miniconda.html

### Issue: "Environment not found"
**Solution:** Make sure to create the environment first with `conda env create -f environment.yml`

### Issue: "Playwright browsers not found"
**Solution:** Run `playwright install chromium` after activating the environment

### Issue: "spaCy model not found"
**Solution:** Run `python -m spacy download es_core_news_sm`

## ğŸ“š Project Structure

```
scrape-to-shape/
â”œâ”€â”€ environment.yml         # Conda environment definition
â”œâ”€â”€ requirements.txt        # Pip dependencies (alternative)
â”œâ”€â”€ setup_env.sh           # Installation script (Linux/Mac)
â”œâ”€â”€ setup_env.bat          # Installation script (Windows)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/               # Raw scraped data
â”‚   â””â”€â”€ processed/         # Cleaned and processed data
â”œâ”€â”€ src/
â”‚   â””â”€â”€ scraper/
â”‚       â”œâ”€â”€ main.py        # Scraper entry point
â”‚       â””â”€â”€ scrapper.py    # Scraping functions
â””â”€â”€ notebooks/
    â””â”€â”€ EDA.ipynb          # Exploratory Data Analysis
```

## ğŸ’¡ Tips

1. **Always activate the environment** before working:
   ```bash
   conda activate scrape-to-shape
   ```

2. **To deactivate** the environment when you're done:
   ```bash
   conda deactivate
   ```

3. **To see installed packages**:
   ```bash
   conda list
   ```

4. **To update a specific package**:
   ```bash
   conda update package_name
   # or with pip:
   pip install --upgrade package_name
   ```

